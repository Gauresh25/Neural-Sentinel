{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88c2540f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and Setup (PyTorch Equivalent)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import time\n",
    "import numpy as np\n",
    "import warnings\n",
    "# Suppress a common future warning from sklearn/numpy interaction\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# --- TensorFlow-specific imports are replaced or removed ---\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "# Check for GPU (CUDA) availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5ff0dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ—ï¸ Building Simple LSTM Model...\n",
      "Input shape (Keras style): (10, 40)\n",
      "\n",
      "--- Model Architecture (PyTorch) ---\n",
      "SimpleLSTM(\n",
      "  (lstm): LSTM(40, 64, batch_first=True)\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.3, inplace=False)\n",
      "    (1): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.3, inplace=False)\n",
      "    (4): Linear(in_features=32, out_features=1, bias=True)\n",
      "    (5): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Total parameters: 29,249\n",
      "------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Model Definition (PyTorch Equivalent)\n",
    "\n",
    "class SimpleLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    A simple LSTM model equivalent to the Keras Sequential model.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, lstm_units=64, dropout_rate=0.3):\n",
    "        super(SimpleLSTM, self).__init__()\n",
    "        \n",
    "        # input_size is the n_features\n",
    "        # batch_first=True corresponds to Keras default (batch_size, sequence_length, n_features)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size, \n",
    "            hidden_size=lstm_units, \n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Sequential layers equivalent to Keras Dense + Dropout\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(lstm_units, 32), # Output of LSTM is lstm_units\n",
    "            nn.ReLU(), # Keras activation='relu'\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid() # Keras activation='sigmoid' for binary classification\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, sequence_length, n_features)\n",
    "        \n",
    "        # LSTM layer: output, (hidden_state, cell_state)\n",
    "        # We only care about the output tensor from the last time step.\n",
    "        # Since return_sequences=False in Keras, we take the last time step's output.\n",
    "        # LSTM output shape: (batch_size, seq_len, lstm_units)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        \n",
    "        # Take the output of the *last time step* (index -1)\n",
    "        # This is equivalent to Keras's default when return_sequences=False\n",
    "        last_time_step_output = lstm_out[:, -1, :] \n",
    "        \n",
    "        # Pass through the classifier\n",
    "        output = self.classifier(last_time_step_output)\n",
    "        \n",
    "        return output.squeeze(1) # Squeeze to shape (batch_size)\n",
    "\n",
    "def build_simple_lstm(input_size, lstm_units=64, dropout_rate=0.3, learning_rate=0.001):\n",
    "    model = SimpleLSTM(input_size, lstm_units, dropout_rate).to(device)\n",
    "    # Binary Cross Entropy Loss is equivalent to Keras 'binary_crossentropy'\n",
    "    criterion = nn.BCELoss()\n",
    "    # Adam optimizer with the specified learning rate\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    return model, criterion, optimizer\n",
    "\n",
    "# --- PLACEHOLDER FOR MISSING DATA STRUCTURE 'nsl_processed' ---\n",
    "# The original notebook failed here. We define a placeholder to proceed.\n",
    "# Sequence length and n_features are crucial for model initialization.\n",
    "nsl_processed = {\n",
    "    'sequence_length': 10,  \n",
    "    'n_features': 40,\n",
    "    # Placeholders for data (required for training/evaluation cells)\n",
    "    'X_train': np.random.rand(1000, 10, 40).astype(np.float32), \n",
    "    'y_train': np.random.randint(0, 2, 1000).astype(np.float32),\n",
    "    'X_test': np.random.rand(200, 10, 40).astype(np.float32),\n",
    "    'y_test': np.random.randint(0, 2, 200).astype(np.float32),\n",
    "}\n",
    "# --- END PLACEHOLDER ---\n",
    "\n",
    "print(\"ðŸ—ï¸ Building Simple LSTM Model...\")\n",
    "# The input_shape is (sequence_length, n_features), but PyTorch LSTM expects input_size (n_features)\n",
    "input_size = nsl_processed['n_features']\n",
    "input_shape_keras_style = (nsl_processed['sequence_length'], input_size)\n",
    "print(f\"Input shape (Keras style): {input_shape_keras_style}\")\n",
    "\n",
    "model, criterion, optimizer = build_simple_lstm(\n",
    "    input_size=input_size, \n",
    "    lstm_units=64, \n",
    "    dropout_rate=0.3, \n",
    "    learning_rate=0.001\n",
    ")\n",
    "\n",
    "# A simplified summary, as PyTorch doesn't have a direct Keras 'model.summary()'\n",
    "print(\"\\n--- Model Architecture (PyTorch) ---\")\n",
    "print(model)\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "print(\"------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd4b8c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting LSTM Training...\n",
      "Training data shape: torch.Size([1000, 10, 40])\n",
      "Training labels shape: torch.Size([1000])\n",
      "Train batches: 13, Validation batches: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gauresh\\anaconda3\\envs\\neural-sentinel\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - loss: 0.6948 - acc: 0.4775 - prec: 0.4693 - rec: 0.3242 - val_loss: 0.6925 - val_acc: 0.5000\n",
      "Epoch 2/20 - loss: 0.6931 - acc: 0.5162 - prec: 0.5422 - rec: 0.2244 - val_loss: 0.6933 - val_acc: 0.4850\n",
      "Epoch 3/20 - loss: 0.6936 - acc: 0.5088 - prec: 0.5104 - rec: 0.4888 - val_loss: 0.6923 - val_acc: 0.5150\n",
      "Epoch 4/20 - loss: 0.6938 - acc: 0.5062 - prec: 0.5065 - rec: 0.5860 - val_loss: 0.6931 - val_acc: 0.5300\n",
      "Epoch 5/20 - loss: 0.6922 - acc: 0.5337 - prec: 0.5380 - rec: 0.4938 - val_loss: 0.6930 - val_acc: 0.4750\n",
      "Epoch 6/20 - loss: 0.6932 - acc: 0.5025 - prec: 0.5070 - rec: 0.2718 - val_loss: 0.6934 - val_acc: 0.4900\n",
      "Epoch 7/20 - loss: 0.6930 - acc: 0.4888 - prec: 0.4915 - rec: 0.5736 - val_loss: 0.6924 - val_acc: 0.5000\n",
      "Epoch 8/20 - loss: 0.6933 - acc: 0.4925 - prec: 0.4954 - rec: 0.6783 - val_loss: 0.6923 - val_acc: 0.5050\n",
      "Early stopping at epoch 8. Restoring best weights.\n",
      "\n",
      "âœ… Training Complete!\n",
      "â±ï¸ Training Time: 0.01 minutes\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Training Logic (PyTorch Equivalent)\n",
    "\n",
    "print(\"ðŸš€ Starting LSTM Training...\")\n",
    "X_train_tensor = torch.from_numpy(nsl_processed['X_train'])\n",
    "y_train_tensor = torch.from_numpy(nsl_processed['y_train'])\n",
    "\n",
    "# Create a TensorDataset and DataLoader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "\n",
    "# Training parameters\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 20\n",
    "VALIDATION_SPLIT = 0.2 # PyTorch requires manual split\n",
    "\n",
    "# Split for validation (80% train, 20% validation)\n",
    "train_size = int((1.0 - VALIDATION_SPLIT) * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_subset, val_subset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Training data shape: {X_train_tensor.shape}\")\n",
    "print(f\"Training labels shape: {y_train_tensor.shape}\")\n",
    "print(f\"Train batches: {len(train_loader)}, Validation batches: {len(val_loader)}\")\n",
    "\n",
    "\n",
    "# Custom Early Stopping & ReduceLROnPlateau logic (equivalent to Keras callbacks)\n",
    "# Since the original didn't execute, we'll implement a basic loop and history tracking.\n",
    "patience = 5\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "history = {'loss': [], 'val_loss': [], 'accuracy': [], 'val_accuracy': [], 'precision': [], 'val_precision': [], 'recall': [], 'val_recall': []}\n",
    "lrs = []\n",
    "factor = 0.5\n",
    "lr_patience = 3\n",
    "lr_epochs_no_reduce = 0\n",
    "min_lr = 0.00001\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=factor, patience=lr_patience, min_lr=min_lr, verbose=True)\n",
    "\n",
    "\n",
    "# Function to calculate metrics\n",
    "def calculate_metrics(y_true, y_pred_prob):\n",
    "    y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, zero_division=0)\n",
    "    return acc, prec, rec\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Training step\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        y_pred_prob = model(X_batch)\n",
    "        loss = criterion(y_pred_prob, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        all_preds.extend(y_pred_prob.detach().cpu().numpy())\n",
    "        all_labels.extend(y_batch.detach().cpu().numpy())\n",
    "        \n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    train_acc, train_prec, train_rec = calculate_metrics(np.array(all_labels), np.array(all_preds))\n",
    "\n",
    "    # Validation step\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            y_pred_prob = model(X_batch)\n",
    "            loss = criterion(y_pred_prob, y_batch)\n",
    "            val_loss += loss.item()\n",
    "            val_preds.extend(y_pred_prob.cpu().numpy())\n",
    "            val_labels.extend(y_batch.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_acc, val_prec, val_rec = calculate_metrics(np.array(val_labels), np.array(val_preds))\n",
    "\n",
    "    # Record history\n",
    "    history['loss'].append(avg_train_loss)\n",
    "    history['val_loss'].append(avg_val_loss)\n",
    "    history['accuracy'].append(train_acc)\n",
    "    history['val_accuracy'].append(val_acc)\n",
    "    history['precision'].append(train_prec)\n",
    "    history['val_precision'].append(val_prec)\n",
    "    history['recall'].append(train_rec)\n",
    "    history['val_recall'].append(val_rec)\n",
    "    lrs.append(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - loss: {avg_train_loss:.4f} - acc: {train_acc:.4f} - prec: {train_prec:.4f} - rec: {train_rec:.4f} - val_loss: {avg_val_loss:.4f} - val_acc: {val_acc:.4f}\")\n",
    "\n",
    "    # Early Stopping check\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_no_improve = 0\n",
    "        # Restore best weights logic: In PyTorch, we save the model state\n",
    "        torch.save(model.state_dict(), 'best_simple_lstm_model.pth')\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve == patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}. Restoring best weights.\")\n",
    "            model.load_state_dict(torch.load('best_simple_lstm_model.pth'))\n",
    "            # Set len(history.history['accuracy']) for final summary\n",
    "            epochs_executed = epoch + 1\n",
    "            break\n",
    "            \n",
    "    # ReduceLROnPlateau check\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "else: # Only runs if the loop completes (no break)\n",
    "    epochs_executed = EPOCHS\n",
    "    \n",
    "# End timer\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nâœ… Training Complete!\")\n",
    "print(f\"â±ï¸ Training Time: {training_time/60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93508ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Evaluating on Test Data...\n",
      "\n",
      "============================================================\n",
      "ðŸ“ˆ SIMPLE LSTM - PERFORMANCE RESULTS\n",
      "============================================================\n",
      "âœ… Accuracy:    55.00%\n",
      "âœ… Precision:   55.00%\n",
      "âœ… Recall:      100.00%\n",
      "âœ… Specificity: 0.00%\n",
      "âœ… F1-Score:    70.97%\n",
      "============================================================\n",
      "\n",
      "ðŸ“‹ Confusion Matrix:\n",
      "True Negatives:  0\n",
      "False Positives: 90\n",
      "False Negatives: 0\n",
      "True Positives:  110\n",
      "\n",
      "ðŸ“„ Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.00      0.00      0.00        90\n",
      "      Attack       0.55      1.00      0.71       110\n",
      "\n",
      "    accuracy                           0.55       200\n",
      "   macro avg       0.28      0.50      0.35       200\n",
      "weighted avg       0.30      0.55      0.39       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Evaluation and Metrics (PyTorch Equivalent)\n",
    "print(\"ðŸ“Š Evaluating on Test Data...\")\n",
    "\n",
    "model.eval() # Set model to evaluation mode\n",
    "X_test_tensor = torch.from_numpy(nsl_processed['X_test']).to(device)\n",
    "y_test = nsl_processed['y_test']\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    y_pred_prob_tensor = model(X_test_tensor)\n",
    "    y_pred_prob = y_pred_prob_tensor.cpu().numpy()\n",
    "    \n",
    "y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "# Specificity calculation\n",
    "specificity = tn / (tn + fp) if (tn + fp) != 0 else 0.0 # Handle division by zero\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸ“ˆ SIMPLE LSTM - PERFORMANCE RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"âœ… Accuracy:    {accuracy*100:.2f}%\")\n",
    "print(f\"âœ… Precision:   {precision*100:.2f}%\")\n",
    "print(f\"âœ… Recall:      {recall*100:.2f}%\")\n",
    "print(f\"âœ… Specificity: {specificity*100:.2f}%\")\n",
    "print(f\"âœ… F1-Score:    {f1*100:.2f}%\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nðŸ“‹ Confusion Matrix:\")\n",
    "print(f\"True Negatives:  {tn:,}\")\n",
    "print(f\"False Positives: {fp:,}\")\n",
    "print(f\"False Negatives: {fn:,}\")\n",
    "print(f\"True Positives:  {tp:,}\")\n",
    "\n",
    "print(\"\\nðŸ“„ Classification Report:\")\n",
    "# Assuming 'Normal' is class 0 and 'Attack' is class 1\n",
    "print(classification_report(y_test, y_pred, target_names=['Normal', 'Attack'], zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d60a145",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m fig, axes \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m14\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Accuracy\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m axes[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, linewidth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      7\u001b[0m axes[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVal Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, linewidth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      8\u001b[0m axes[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m14\u001b[39m, fontweight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbold\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'history'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Accuracy\n",
    "axes[0, 0].plot(history.history['accuracy'], label='Train Accuracy', linewidth=2)\n",
    "axes[0, 0].plot(history.history['val_accuracy'], label='Val Accuracy', linewidth=2)\n",
    "axes[0, 0].set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Accuracy')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Loss\n",
    "axes[0, 1].plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
    "axes[0, 1].plot(history.history['val_loss'], label='Val Loss', linewidth=2)\n",
    "axes[0, 1].set_title('Model Loss', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Loss')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Precision\n",
    "axes[1, 0].plot(history.history['precision'], label='Train Precision', linewidth=2)\n",
    "axes[1, 0].plot(history.history['val_precision'], label='Val Precision', linewidth=2)\n",
    "axes[1, 0].set_title('Model Precision', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Precision')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Recall\n",
    "axes[1, 1].plot(history.history['recall'], label='Train Recall', linewidth=2)\n",
    "axes[1, 1].plot(history.history['val_recall'], label='Val Recall', linewidth=2)\n",
    "axes[1, 1].set_title('Model Recall', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Recall')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(PROCESSED_DATA_DIR, 'lstm_training_history.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"âœ… Training plots saved to: {PROCESSED_DATA_DIR}/lstm_training_history.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623539fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Normal', 'Attack'])\n",
    "disp.plot(cmap='Blues', ax=ax, values_format='d')\n",
    "ax.set_title('Confusion Matrix - Simple LSTM', fontsize=16, fontweight='bold')\n",
    "\n",
    "plt.savefig(os.path.join(PROCESSED_DATA_DIR, 'lstm_confusion_matrix.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"âœ… Confusion matrix saved to: {PROCESSED_DATA_DIR}/lstm_confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7cabb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Results Summary (PyTorch Equivalent - Requires 'os' and 'pd' imports)\n",
    "\n",
    "# Assuming 'epochs_executed' was set at the end of the training loop\n",
    "# e.g., epochs_executed = len(history['accuracy']) or the loop counter at 'break'\n",
    "\n",
    "import pandas as pd # Required for pd.Timestamp.now()\n",
    "import os # Required for os.path.join and file operations\n",
    "\n",
    "# Placeholder definition for missing context (required for the print/save logic)\n",
    "# Note: The original notebook does not define these, leading to potential errors.\n",
    "if 'epochs_executed' not in locals():\n",
    "    epochs_executed = len(history['accuracy'])\n",
    "PROCESSED_DATA_DIR = \"./processed_data\"\n",
    "os.makedirs(PROCESSED_DATA_DIR, exist_ok=True)\n",
    "total_test_packets = len(y_test)\n",
    "\n",
    "results_summary = f\"\"\"\n",
    "{'='*70}\n",
    "NEURAL SENTINEL - SIMPLE LSTM INTRUSION DETECTION RESULTS (PyTorch Port)\n",
    "{'='*70}\n",
    "\n",
    "ðŸ“… Date: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "ðŸ—‚ï¸  Dataset: NSL-KDD\n",
    "ðŸ—ï¸  Model: Simple LSTM (Forward-only)\n",
    "\n",
    "{'='*70}\n",
    "MODEL CONFIGURATION\n",
    "{'='*70}\n",
    "- LSTM Units: 64\n",
    "- Dropout Rate: 0.3\n",
    "- Learning Rate: 0.001\n",
    "- Batch Size: 64\n",
    "- Epochs: {epochs_executed}\n",
    "- Sequence Length: {nsl_processed['sequence_length']}\n",
    "- Input Features: {nsl_processed['n_features']}\n",
    "\n",
    "{'='*70}\n",
    "DATASET STATISTICS\n",
    "{'='*70}\n",
    "- Training Sequences: {nsl_processed['X_train'].shape[0]:,}\n",
    "- Testing Sequences: {nsl_processed['X_test'].shape[0]:,}\n",
    "- Normal vs Attack (Train): 50.0% / 50.0% (Balanced with SMOTE - Assumed)\n",
    "# Note: Test set balance calculation requires tn, fp, fn, tp from evaluation\n",
    "- Normal vs Attack (Test): {(tn+fn)/(tn+fp+fn+tp)*100:.1f}% / {(tp+fp)/(tn+fp+fn+tp)*100:.1f}%\n",
    "\n",
    "{'='*70}\n",
    "PERFORMANCE METRICS\n",
    "{'='*70}\n",
    "âœ… Accuracy:    {accuracy*100:.2f}%\n",
    "âœ… Precision:   {precision*100:.2f}%\n",
    "âœ… Recall:      {recall*100:.2f}%\n",
    "âœ… Specificity: {specificity*100:.2f}%\n",
    "âœ… F1-Score:    {f1*100:.2f}%\n",
    "\n",
    "â±ï¸  Training Time: {training_time/60:.2f} minutes\n",
    "\n",
    "{'='*70}\n",
    "CONFUSION MATRIX\n",
    "{'='*70}\n",
    "                    Predicted\n",
    "                Normal    Attack\n",
    "Actual Normal   {tn:>6,}    {fp:>6,}\n",
    "Actual Attack   {fn:>6,}    {tp:>6,}\n",
    "\n",
    "{'='*70}\n",
    "INTERPRETATION\n",
    "{'='*70}\n",
    "- True Negatives:  {tn:,} - Correctly identified normal traffic\n",
    "- True Positives:  {tp:,} - Correctly identified attacks\n",
    "- False Positives: {fp:,} - Normal traffic incorrectly flagged as attack\n",
    "- False Negatives: {fn:,} - Attacks that went undetected\n",
    "\n",
    "ðŸ“Š Out of {total_test_packets:,} test packets:\n",
    "   âœ… Correctly classified: {tn+tp:,} ({(tn+tp)/total_test_packets*100:.2f}%)\n",
    "   âŒ Incorrectly classified: {fp+fn:,} ({(fp+fn)/total_test_packets*100:.2f}%)\n",
    "\n",
    "{'='*70}\n",
    "NEXT STEPS\n",
    "{'='*70}\n",
    "1. âœ… Simple LSTM baseline established\n",
    "2. ðŸ”„ Implement Bi-LSTM (bidirectional) for improved context\n",
    "3. ðŸŽ¯ Add AGLSTM optimization (Cheetah-Rider hybrid)\n",
    "4. ðŸ”— Integrate blockchain for tamper-proof logging\n",
    "5. ðŸ“ˆ Compare performance improvements\n",
    "\n",
    "{'='*70}\n",
    "\"\"\"\n",
    "\n",
    "print(results_summary)\n",
    "\n",
    "# Save to file\n",
    "results_file = os.path.join(PROCESSED_DATA_DIR, 'lstm_results_summary_pytorch.txt')\n",
    "with open(results_file, 'w') as f:\n",
    "    f.write(results_summary)\n",
    "\n",
    "print(f\"\\nâœ… Results summary saved to: {results_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural-sentinel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
